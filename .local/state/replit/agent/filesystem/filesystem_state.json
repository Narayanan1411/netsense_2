{"file_contents":{"app.py":{"content":"import streamlit as st\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport numpy as np\nimport io\nimport json\nfrom typing import Dict, Any\nimport traceback\n\nfrom network_optimizer import NetworkOptimizer\nfrom utils import validate_csv_structure, get_sample_data_info\n\n# Configure page\nst.set_page_config(\n    page_title=\"Provider Network Optimizer\",\n    page_icon=\"ðŸ¥\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\ndef main():\n    st.title(\"ðŸ¥ Provider Network Optimizer Dashboard\")\n    st.markdown(\"Upload provider and member CSV files to optimize your healthcare network\")\n    \n    # Initialize session state\n    if 'optimization_results' not in st.session_state:\n        st.session_state.optimization_results = None\n    if 'processed_data' not in st.session_state:\n        st.session_state.processed_data = None\n    \n    # Sidebar for file uploads and configuration\n    with st.sidebar:\n        st.header(\"ðŸ“ Data Upload\")\n        \n        # Display sample data requirements\n        with st.expander(\"ðŸ“‹ Required CSV Format\", expanded=False):\n            st.markdown(get_sample_data_info())\n        \n        # File upload sections\n        st.subheader(\"Provider Data\")\n        provider_file = st.file_uploader(\n            \"Upload Provider CSV\",\n            type=['csv'],\n            key=\"provider_upload\",\n            help=\"CSV file containing provider information\"\n        )\n        \n        st.subheader(\"Member Data\")\n        member_file = st.file_uploader(\n            \"Upload Member CSV\",\n            type=['csv'],\n            key=\"member_upload\",\n            help=\"CSV file containing member information\"\n        )\n        \n        # Configuration options\n        st.header(\"âš™ï¸ Configuration\")\n        \n        max_drive_time = st.slider(\n            \"Max Drive Time (minutes)\",\n            min_value=10,\n            max_value=60,\n            value=30,\n            step=5,\n            help=\"Maximum acceptable drive time from member to provider\"\n        )\n        \n        min_coverage = st.slider(\n            \"Minimum Coverage (%)\",\n            min_value=80.0,\n            max_value=100.0,\n            value=95.0,\n            step=1.0,\n            help=\"Minimum percentage of members that must be covered\"\n        )\n        \n        min_rating = st.slider(\n            \"Minimum Average Rating\",\n            min_value=1.0,\n            max_value=5.0,\n            value=3.0,\n            step=0.1,\n            help=\"Minimum acceptable average provider rating\"\n        )\n    \n    # Main content area\n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        if provider_file is not None and member_file is not None:\n            if st.button(\"ðŸš€ Run Optimization\", type=\"primary\", use_container_width=True):\n                run_optimization(provider_file, member_file, max_drive_time, min_coverage, min_rating)\n        else:\n            st.info(\"ðŸ‘† Please upload both provider and member CSV files to begin optimization\")\n    \n    with col2:\n        if st.session_state.optimization_results is not None:\n            if st.button(\"ðŸ“¥ Export Results\", use_container_width=True):\n                export_results()\n    \n    # Display results if available\n    if st.session_state.optimization_results is not None:\n        display_results()\n    \n    # Display file previews\n    display_file_previews(provider_file, member_file)\n\ndef run_optimization(provider_file, member_file, max_drive_time, min_coverage, min_rating):\n    \"\"\"Run the network optimization process\"\"\"\n    with st.spinner(\"ðŸ”„ Processing data and running optimization...\"):\n        try:\n            # Read and validate CSV files\n            providers_df = pd.read_csv(provider_file)\n            members_df = pd.read_csv(member_file)\n            \n            # Validate CSV structure\n            provider_validation = validate_csv_structure(providers_df, 'provider')\n            member_validation = validate_csv_structure(members_df, 'member')\n            \n            if not provider_validation['valid']:\n                st.error(f\"âŒ Provider CSV validation failed: {provider_validation['message']}\")\n                return\n            \n            if not member_validation['valid']:\n                st.error(f\"âŒ Member CSV validation failed: {member_validation['message']}\")\n                return\n            \n            # Initialize optimizer with configuration\n            optimizer = NetworkOptimizer(\n                max_drive_min=max_drive_time,\n                min_coverage_pct=min_coverage,\n                min_avg_rating=min_rating\n            )\n            \n            # Run optimization with progress tracking\n            progress_bar = st.progress(0)\n            status_text = st.empty()\n            progress_container = st.container()\n            \n            status_text.text(\"ðŸ” Analyzing provider data...\")\n            progress_bar.progress(20)\n            \n            status_text.text(\"ðŸ‘¥ Processing member data...\")\n            progress_bar.progress(40)\n            \n            status_text.text(\"ðŸ§® Building candidate pairs...\")\n            progress_bar.progress(60)\n            \n            status_text.text(\"âš¡ Running optimization algorithm...\")\n            progress_bar.progress(80)\n            \n            # Add a live log container for real-time updates\n            log_container = progress_container.empty()\n            \n            class StreamlitProgressHandler:\n                def __init__(self, log_container, status_text):\n                    self.log_container = log_container\n                    self.status_text = status_text\n                    self.removed_count = 0\n                    self.logs = []\n                \n                def update_progress(self, message):\n                    if \"Removed provider\" in message:\n                        self.removed_count += 1\n                        self.status_text.text(f\"ðŸ”§ Optimizing network... Removed {self.removed_count} providers\")\n                        # Keep only last 10 log entries\n                        self.logs.append(message)\n                        if len(self.logs) > 10:\n                            self.logs.pop(0)\n                        self.log_container.text(\"\\n\".join(self.logs[-5:]))  # Show last 5 entries\n            \n            # Create progress handler and pass to optimizer\n            progress_handler = StreamlitProgressHandler(log_container, status_text)\n            optimizer.progress_handler = progress_handler\n            \n            results = optimizer.optimize(members_df, providers_df)\n            \n            status_text.text(\"âœ… Optimization complete!\")\n            progress_bar.progress(100)\n            \n            # Store results in session state\n            st.session_state.optimization_results = results\n            st.session_state.processed_data = {\n                'providers': providers_df,\n                'members': members_df,\n                'config': {\n                    'max_drive_time': max_drive_time,\n                    'min_coverage': min_coverage,\n                    'min_rating': min_rating\n                }\n            }\n            \n            # Clear progress indicators\n            progress_bar.empty()\n            status_text.empty()\n            \n            st.success(\"ðŸŽ‰ Network optimization completed successfully!\")\n            st.rerun()\n            \n        except Exception as e:\n            st.error(f\"âŒ Error during optimization: {str(e)}\")\n            st.expander(\"ðŸ” Error Details\", expanded=False).code(traceback.format_exc())\n\ndef display_results():\n    \"\"\"Display optimization results with visualizations\"\"\"\n    results = st.session_state.optimization_results\n    data = st.session_state.processed_data\n    \n    st.header(\"ðŸ“Š Optimization Results\")\n    \n    # Key metrics row\n    col1, col2, col3, col4 = st.columns(4)\n    \n    with col1:\n        st.metric(\n            \"Coverage\",\n            f\"{results['coverage_pct']:.1f}%\",\n            help=\"Percentage of members assigned to providers\"\n        )\n    \n    with col2:\n        st.metric(\n            \"Average Rating\",\n            f\"{results['avg_rating']:.2f}\",\n            help=\"Average CMS rating of selected providers\"\n        )\n    \n    with col3:\n        st.metric(\n            \"Total Cost\",\n            f\"${results['total_cost']:,.0f}\",\n            help=\"Total annual cost of selected providers\"\n        )\n    \n    with col4:\n        st.metric(\n            \"Providers Used\",\n            f\"{results['providers_used']}\",\n            help=\"Number of providers in optimized network\"\n        )\n    \n    # Before vs After Comparison\n    display_before_after_comparison(results, data)\n    \n    # Tabs for different views\n    tab1, tab2, tab3 = st.tabs([\"ðŸ“ˆ Analytics\", \"ðŸ“‹ Assignments\", \"ðŸ“Š Provider Details\"])\n    \n    with tab1:\n        display_analytics(results, data)\n    \n    with tab2:\n        display_assignments(results)\n    \n    with tab3:\n        display_provider_details(results, data)\n\ndef display_analytics(results, data):\n    \"\"\"Display analytics charts and insights\"\"\"\n    assignments = results['final_assignments']\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        # Provider type distribution\n        if not assignments.empty:\n            type_counts = assignments['ProviderType'].value_counts()\n            fig_pie = px.pie(\n                values=type_counts.values,\n                names=type_counts.index,\n                title=\"Provider Distribution by Type\"\n            )\n            st.plotly_chart(fig_pie, use_container_width=True)\n    \n    with col2:\n        # Rating distribution\n        if not assignments.empty:\n            fig_hist = px.histogram(\n                assignments,\n                x='CMS_Rating',\n                nbins=10,\n                title=\"Provider Rating Distribution\",\n                labels={'CMS_Rating': 'CMS Rating', 'count': 'Number of Providers'}\n            )\n            st.plotly_chart(fig_hist, use_container_width=True)\n    \n    # Cost analysis\n    if not assignments.empty:\n        provider_costs = assignments.groupby('ProviderId').agg({\n            'Cost': 'first',\n            'MemberId': 'count',\n            'CMS_Rating': 'first'\n        }).rename(columns={'MemberId': 'Members_Assigned'})\n        \n        provider_costs['Cost_Per_Member'] = provider_costs['Cost'] / provider_costs['Members_Assigned']\n        \n        fig_scatter = px.scatter(\n            provider_costs,\n            x='Members_Assigned',\n            y='Cost_Per_Member',\n            color='CMS_Rating',\n            size='Cost',\n            title=\"Provider Cost Efficiency Analysis\",\n            labels={\n                'Members_Assigned': 'Members Assigned',\n                'Cost_Per_Member': 'Cost per Member ($)',\n                'CMS_Rating': 'CMS Rating'\n            },\n            hover_data={'Cost': ':,.0f'}\n        )\n        st.plotly_chart(fig_scatter, use_container_width=True)\n\ndef display_before_after_comparison(results, data):\n    \"\"\"Display comprehensive before vs after optimization comparison\"\"\"\n    st.subheader(\"ðŸ”„ Before vs After Optimization\")\n    \n    # Calculate original network metrics\n    providers_df = data['providers']\n    members_df = data['members']\n    \n    # Original network metrics (all providers)\n    original_cost = providers_df['Cost'].sum()\n    original_providers = len(providers_df)\n    original_avg_rating = providers_df['CMS_Rating'].mean()\n    \n    # Optimized network metrics\n    optimized_cost = results['total_cost']\n    optimized_providers = results['providers_used']\n    optimized_avg_rating = results['avg_rating']\n    optimized_coverage = results['coverage_pct']\n    \n    # Calculate savings\n    cost_savings = original_cost - optimized_cost\n    savings_percentage = (cost_savings / original_cost) * 100\n    providers_removed = original_providers - optimized_providers\n    reduction_percentage = (providers_removed / original_providers) * 100\n    \n    # Main comparison metrics\n    col1, col2, col3, col4 = st.columns(4)\n    \n    with col1:\n        st.metric(\n            \"Network Cost\",\n            f\"${optimized_cost:,.0f}\",\n            delta=f\"-${cost_savings:,.0f} ({savings_percentage:.1f}%)\",\n            delta_color=\"inverse\"\n        )\n    \n    with col2:\n        st.metric(\n            \"Providers Used\",\n            f\"{optimized_providers}\",\n            delta=f\"-{providers_removed} ({reduction_percentage:.1f}%)\",\n            delta_color=\"inverse\"\n        )\n    \n    with col3:\n        rating_change = optimized_avg_rating - original_avg_rating\n        st.metric(\n            \"Average Rating\",\n            f\"{optimized_avg_rating:.2f}\",\n            delta=f\"{rating_change:+.2f}\",\n            delta_color=\"normal\"\n        )\n    \n    with col4:\n        st.metric(\n            \"Member Coverage\",\n            f\"{optimized_coverage:.1f}%\",\n            help=\"Percentage of members assigned to providers\"\n        )\n    \n    # Detailed comparison charts\n    st.subheader(\"ðŸ“Š Detailed Comparison\")\n    \n    col1, col2 = st.columns(2)\n    \n    with col1:\n        # Cost comparison bar chart\n        comparison_data = {\n            'Network': ['Original', 'Optimized'],\n            'Cost': [original_cost, optimized_cost]\n        }\n        fig_cost = px.bar(\n            comparison_data,\n            x='Network',\n            y='Cost',\n            title=\"Total Network Cost Comparison\",\n            color='Network',\n            color_discrete_map={'Original': '#ff7f7f', 'Optimized': '#7fbf7f'}\n        )\n        fig_cost.update_layout(showlegend=False)\n        st.plotly_chart(fig_cost, use_container_width=True)\n    \n    with col2:\n        # Provider count comparison\n        comparison_providers = {\n            'Network': ['Original', 'Optimized'],\n            'Providers': [original_providers, optimized_providers]\n        }\n        fig_providers = px.bar(\n            comparison_providers,\n            x='Network',\n            y='Providers',\n            title=\"Provider Count Comparison\",\n            color='Network',\n            color_discrete_map={'Original': '#ff7f7f', 'Optimized': '#7fbf7f'}\n        )\n        fig_providers.update_layout(showlegend=False)\n        st.plotly_chart(fig_providers, use_container_width=True)\n    \n    # Summary insights\n    st.subheader(\"ðŸ’¡ Key Insights\")\n    \n    insights = []\n    insights.append(f\"**Cost Savings**: Achieved ${cost_savings:,.0f} savings ({savings_percentage:.1f}% reduction)\")\n    insights.append(f\"**Network Efficiency**: Reduced provider count by {providers_removed} ({reduction_percentage:.1f}%)\")\n    \n    if rating_change > 0:\n        insights.append(f\"**Quality Improvement**: Average provider rating increased by {rating_change:.2f} points\")\n    elif rating_change < -0.1:\n        insights.append(f\"**Quality Trade-off**: Average provider rating decreased by {abs(rating_change):.2f} points\")\n    else:\n        insights.append(f\"**Quality Maintained**: Average provider rating remained stable\")\n    \n    insights.append(f\"**Coverage**: {optimized_coverage:.1f}% of members successfully assigned to providers\")\n    \n    for insight in insights:\n        st.write(f\"â€¢ {insight}\")\n    \n    # Provider type analysis if available\n    assignments = results['final_assignments']\n    if not assignments.empty and 'ProviderType' in assignments.columns:\n        st.subheader(\"ðŸ¥ Provider Type Analysis\")\n        \n        # Original provider types\n        original_types = providers_df['ProviderType'].value_counts() if 'ProviderType' in providers_df.columns else None\n        \n        # Optimized provider types\n        optimized_types = assignments['ProviderType'].value_counts()\n        \n        if original_types is not None:\n            # Create comparison dataframe\n            comparison_df = pd.DataFrame({\n                'Original': original_types,\n                'Optimized': optimized_types\n            }).fillna(0)\n            \n            # Provider type comparison chart\n            fig_types = px.bar(\n                comparison_df.reset_index(),\n                x='ProviderType',\n                y=['Original', 'Optimized'],\n                title=\"Provider Count by Type: Before vs After\",\n                barmode='group'\n            )\n            st.plotly_chart(fig_types, use_container_width=True)\n\ndef display_assignments(results):\n    \"\"\"Display member-provider assignments table\"\"\"\n    assignments = results['final_assignments']\n    \n    if assignments.empty:\n        st.warning(\"No assignments to display\")\n        return\n    \n    # Summary statistics\n    col1, col2, col3 = st.columns(3)\n    \n    with col1:\n        avg_rating = assignments['CMS_Rating'].mean()\n        st.metric(\"Avg Provider Rating\", f\"{avg_rating:.2f}\")\n    \n    with col2:\n        total_members = len(assignments)\n        st.metric(\"Total Assignments\", f\"{total_members:,}\")\n    \n    with col3:\n        unique_providers = assignments['ProviderId'].nunique()\n        st.metric(\"Unique Providers\", f\"{unique_providers}\")\n    \n    # Assignments table with filtering\n    st.subheader(\"Assignment Details\")\n    \n    # Filters\n    col1, col2, col3 = st.columns(3)\n    \n    with col1:\n        provider_types = ['All'] + sorted(assignments['ProviderType'].unique().tolist())\n        selected_type = st.selectbox(\"Filter by Provider Type\", provider_types)\n    \n    with col2:\n        min_rating_filter = st.slider(\"Minimum Rating\", 1.0, 5.0, 1.0, 0.1)\n    \n    with col3:\n        max_cost_filter = st.number_input(\n            \"Maximum Cost\", \n            min_value=0,\n            max_value=int(assignments['Cost'].max()),\n            value=int(assignments['Cost'].max())\n        )\n    \n    # Apply filters\n    filtered_assignments = assignments.copy()\n    \n    if selected_type != 'All':\n        filtered_assignments = filtered_assignments[filtered_assignments['ProviderType'] == selected_type]\n    \n    filtered_assignments = filtered_assignments[\n        (filtered_assignments['CMS_Rating'] >= min_rating_filter) &\n        (filtered_assignments['Cost'] <= max_cost_filter)\n    ]\n    \n    # Display filtered table\n    st.dataframe(\n        filtered_assignments[['MemberId', 'ProviderId', 'ProviderType', 'CMS_Rating', 'Cost']],\n        use_container_width=True,\n        hide_index=True\n    )\n    \n    # Download filtered data\n    if not filtered_assignments.empty:\n        csv_data = filtered_assignments.to_csv(index=False)\n        st.download_button(\n            label=\"ðŸ“¥ Download Filtered Assignments\",\n            data=csv_data,\n            file_name=\"filtered_assignments.csv\",\n            mime=\"text/csv\"\n        )\n\ndef display_provider_details(results, data):\n    \"\"\"Display detailed provider information\"\"\"\n    assignments = results['final_assignments']\n    \n    if assignments.empty:\n        st.warning(\"No provider details to display\")\n        return\n    \n    # Provider utilization analysis\n    provider_stats = assignments.groupby(['ProviderId', 'ProviderType', 'CMS_Rating', 'Cost']).size().reset_index(name='Members_Assigned')\n    \n    # Sort by members assigned\n    provider_stats = provider_stats.sort_values('Members_Assigned', ascending=False)\n    \n    st.subheader(\"Provider Utilization\")\n    \n    # Top providers chart\n    top_providers = provider_stats.head(15)\n    fig_bar = px.bar(\n        top_providers,\n        x='ProviderId',\n        y='Members_Assigned',\n        color='CMS_Rating',\n        title=\"Top 15 Providers by Member Assignment\",\n        labels={'ProviderId': 'Provider ID', 'Members_Assigned': 'Members Assigned'}\n    )\n    fig_bar.update_layout(xaxis={'tickangle': 45})\n    st.plotly_chart(fig_bar, use_container_width=True)\n    \n    # Detailed provider table\n    st.subheader(\"Provider Summary\")\n    provider_stats['Cost_Per_Member'] = provider_stats['Cost'] / provider_stats['Members_Assigned']\n    \n    # Format columns for display\n    display_stats = provider_stats.copy()\n    display_stats['Cost'] = display_stats['Cost'].apply(lambda x: f\"${x:,.0f}\")\n    display_stats['Cost_Per_Member'] = display_stats['Cost_Per_Member'].apply(lambda x: f\"${x:,.0f}\")\n    display_stats['CMS_Rating'] = display_stats['CMS_Rating'].apply(lambda x: f\"{x:.1f}\")\n    \n    st.dataframe(\n        display_stats[['ProviderId', 'ProviderType', 'CMS_Rating', 'Members_Assigned', 'Cost', 'Cost_Per_Member']],\n        use_container_width=True,\n        hide_index=True,\n        column_config={\n            'ProviderId': 'Provider ID',\n            'ProviderType': 'Type',\n            'CMS_Rating': 'Rating',\n            'Members_Assigned': 'Members',\n            'Cost': 'Annual Cost',\n            'Cost_Per_Member': 'Cost/Member'\n        }\n    )\n\ndef display_file_previews(provider_file, member_file):\n    \"\"\"Display previews of uploaded files\"\"\"\n    if provider_file is not None or member_file is not None:\n        st.header(\"ðŸ“‹ Data Preview\")\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            if provider_file is not None:\n                st.subheader(\"Provider Data Preview\")\n                try:\n                    provider_df = pd.read_csv(provider_file)\n                    st.dataframe(provider_df.head(10), use_container_width=True)\n                    st.caption(f\"Shape: {provider_df.shape[0]} rows Ã— {provider_df.shape[1]} columns\")\n                except Exception as e:\n                    st.error(f\"Error reading provider file: {str(e)}\")\n        \n        with col2:\n            if member_file is not None:\n                st.subheader(\"Member Data Preview\")\n                try:\n                    member_df = pd.read_csv(member_file)\n                    st.dataframe(member_df.head(10), use_container_width=True)\n                    st.caption(f\"Shape: {member_df.shape[0]} rows Ã— {member_df.shape[1]} columns\")\n                except Exception as e:\n                    st.error(f\"Error reading member file: {str(e)}\")\n\ndef export_results():\n    \"\"\"Export optimization results to downloadable formats\"\"\"\n    if st.session_state.optimization_results is None:\n        st.error(\"No results to export\")\n        return\n    \n    results = st.session_state.optimization_results\n    \n    # Create export data\n    assignments = results['final_assignments']\n    \n    if assignments.empty:\n        st.warning(\"No assignments to export\")\n        return\n    \n    # Export options\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        # CSV export\n        csv_data = assignments.to_csv(index=False)\n        st.download_button(\n            label=\"ðŸ“„ Download as CSV\",\n            data=csv_data,\n            file_name=\"network_optimization_results.csv\",\n            mime=\"text/csv\",\n            use_container_width=True\n        )\n    \n    with col2:\n        # JSON export with summary\n        export_data = {\n            'optimization_summary': {\n                'coverage_pct': results['coverage_pct'],\n                'avg_rating': results['avg_rating'],\n                'total_cost': results['total_cost'],\n                'providers_used': results['providers_used']\n            },\n            'assignments': assignments.to_dict('records')\n        }\n        \n        json_data = json.dumps(export_data, indent=2, default=str)\n        st.download_button(\n            label=\"ðŸ“Š Download as JSON\",\n            data=json_data,\n            file_name=\"network_optimization_results.json\",\n            mime=\"application/json\",\n            use_container_width=True\n        )\n    \n    st.success(\"âœ… Export options ready!\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":23530},"network_optimizer.py":{"content":"import logging\nimport json\nimport os\nfrom typing import Any, Dict, Iterable, List, Tuple, Optional\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.spatial import cKDTree\nfrom numba import njit\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\nlogger = logging.getLogger(\"network_optimizer_enhanced\")\n\n# Default configuration constants\nDEFAULT_MAX_DRIVE_MIN = 30.0\nDEFAULT_MIN_COVERAGE_PCT = 95.0\nDEFAULT_MIN_AVG_RATING = 3.0\nTARGET_REDUCTION = (0.08, 0.12)\nMINUTES_PER_KM = 1.2\nK_NEAREST_PROVIDERS = 50\nMAX_REMOVAL_CANDIDATES = 5000\n\n# Provider type mappings\nTYPE_CANONICAL = {\n    \"hospital\": [\"hospital\", \"hosp\", \"acute care\", \"psychiatric\", \"rehabilitation\", \"children\"],\n    \"nursing_home\": [\"nursing\", \"home health\", \"assisted living\", \"foster care\", \"hospice\", \"residential care\", \"skilled nursing\"],\n    \"scan_center\": [\"scan\", \"imaging\", \"mri\", \"ct\", \"x-ray\", \"ultrasound\"],\n    \"clinic\": [\"clinic\", \"outpatient\", \"primary care\", \"pediatrician\", \"optometrist\", \"obstetric\"],\n    \"supplier_directory\": [\"supplier\", \"directory\", \"pharmacy\", \"medical supply\", \"optical\", \"durable medical\", \"optician\", \"orthotic\", \"prosthetic\"],\n    \"other\": [\"grocery\", \"department store\"]\n}\n\nTYPE_MIN_COUNTS = {\n    \"hospital\": 1,\n    \"nursing_home\": 0,\n    \"scan_center\": 0,\n    \"clinic\": 1,\n    \"supplier_directory\": 0\n}\n\n@njit\ndef haversine_km_numba(lat1, lon1, lat2, lon2):\n    \"\"\"Calculate haversine distance in kilometers using Numba JIT\"\"\"\n    R = 6371.0\n    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n    dlon = lon2_rad - lon1_rad\n    dlat = lat2_rad - lat1_rad\n    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2.0) ** 2\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n    return R * c\n\ndef find_col(df: pd.DataFrame, candidates: Iterable[str]) -> Optional[str]:\n    \"\"\"Find column name from candidates\"\"\"\n    cols = list(df.columns)\n    lowered = {c.lower().replace(\" \", \"\").replace(\"_\", \"\"): c for c in cols}\n    \n    for cand in candidates:\n        key = cand.lower().replace(\" \", \"\").replace(\"_\", \"\")\n        if key in lowered:\n            return lowered[key]\n    \n    for cand in candidates:\n        if cand in cols:\n            return cand\n    \n    return None\n\ndef map_columns_providers(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Map provider columns to standard names\"\"\"\n    col_map = {\n        \"ProviderId\": find_col(df, [\"providerid\", \"provider id\", \"provider_id\", \"id\"]),\n        \"Source\": find_col(df, [\"source\"]),\n        \"Type\": find_col(df, [\"type\", \"facilitytype\", \"facility_type\"]),\n        \"Latitude\": find_col(df, [\"latitude\", \"lat\", \"latt\"]),\n        \"Longitude\": find_col(df, [\"longitude\", \"lon\", \"lng\"]),\n        \"CMS_Rating\": find_col(df, [\"cmsrating\", \"cms rating\", \"rating\", \"star\", \"cms_rating\"]),\n        \"Availability\": find_col(df, [\"availability\", \"capacity\", \"avail\"]),\n        \"Cost\": find_col(df, [\"cost\", \"annualcost\", \"contractcost\", \"annual_cost\", \"contract_cost\"])\n    }\n    \n    rename_map = {v: k for k, v in col_map.items() if v}\n    mapped_df = df.rename(columns=rename_map)\n    \n    # Validate required columns\n    required_cols = [\"ProviderId\", \"Latitude\", \"Longitude\"]\n    missing_cols = [col for col in required_cols if col not in mapped_df.columns]\n    \n    if missing_cols:\n        raise ValueError(f\"Missing required provider columns: {missing_cols}\")\n    \n    # Fill missing optional columns with defaults\n    if \"CMS_Rating\" not in mapped_df.columns:\n        mapped_df[\"CMS_Rating\"] = 3.0\n    if \"Cost\" not in mapped_df.columns:\n        mapped_df[\"Cost\"] = 100000.0\n    if \"Availability\" not in mapped_df.columns:\n        mapped_df[\"Availability\"] = 1.0\n    \n    return mapped_df\n\ndef map_columns_members(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Map member columns to standard names\"\"\"\n    col_map = {\n        \"MemberId\": find_col(df, [\"memberid\", \"member id\", \"member_id\", \"id\"]),\n        \"Latitude\": find_col(df, [\"latitude\", \"lat\"]),\n        \"Longitude\": find_col(df, [\"longitude\", \"lon\", \"lng\"])\n    }\n    \n    rename_map = {v: k for k, v in col_map.items() if v}\n    mapped_df = df.rename(columns=rename_map)\n    \n    # Validate required columns\n    required_cols = [\"MemberId\", \"Latitude\", \"Longitude\"]\n    missing_cols = [col for col in required_cols if col not in mapped_df.columns]\n    \n    if missing_cols:\n        raise ValueError(f\"Missing required member columns: {missing_cols}\")\n    \n    return mapped_df\n\ndef normalize_provider_type(t: Any) -> str:\n    \"\"\"Normalize provider type to canonical form\"\"\"\n    if pd.isna(t):\n        return \"other\"\n    \n    s = str(t).strip().lower()\n    for canon, examples in TYPE_CANONICAL.items():\n        for ex in examples:\n            if ex in s:\n                return canon\n    \n    return \"other\"\n\ndef apply_type_normalization(providers: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Apply provider type normalization\"\"\"\n    prov = providers.copy()\n    raw = prov.get(\"Type\", prov.get(\"Source\", pd.Series([\"other\"] * len(prov))))\n    prov[\"ProviderType\"] = raw.fillna(\"other\").astype(str).apply(normalize_provider_type)\n    return prov\n\ndef build_candidate_pairs(members: pd.DataFrame, providers: pd.DataFrame, max_drive_min: float) -> pd.DataFrame:\n    \"\"\"Build member-provider candidate pairs using k-d tree\"\"\"\n    if members.empty or providers.empty:\n        return pd.DataFrame(columns=['MemberId', 'ProviderId', 'DriveTimeMin'])\n    \n    logger.info(\"Building provider k-d tree for fast spatial queries...\")\n    provider_coords = providers[['Latitude', 'Longitude']].to_numpy()\n    provider_tree = cKDTree(provider_coords)\n    \n    member_coords = members[['Latitude', 'Longitude']].to_numpy()\n    max_dist_in_degrees = max_drive_min / MINUTES_PER_KM / 111.0\n    \n    logger.info(f\"Querying for the {K_NEAREST_PROVIDERS} nearest providers for each member...\")\n    distances, indices = provider_tree.query(\n        member_coords, \n        k=K_NEAREST_PROVIDERS, \n        distance_upper_bound=max_dist_in_degrees, \n        workers=-1\n    )\n    \n    logger.info(\"Filtering and building final candidate list...\")\n    valid_pairs = []\n    member_ids = members['MemberId'].values\n    provider_ids = providers['ProviderId'].values\n    \n    for i in range(len(member_coords)):\n        for j in range(K_NEAREST_PROVIDERS):\n            provider_idx = indices[i, j]\n            if provider_idx < len(providers):\n                dist_km = haversine_km_numba(\n                    member_coords[i, 0], member_coords[i, 1],\n                    provider_coords[provider_idx, 0], provider_coords[provider_idx, 1]\n                )\n                drive_time = dist_km * MINUTES_PER_KM\n                if drive_time <= max_drive_min:\n                    valid_pairs.append((member_ids[i], provider_ids[provider_idx], drive_time))\n    \n    if not valid_pairs:\n        logger.warning(\"No member-provider pairs found within %.1f minutes.\", max_drive_min)\n        return pd.DataFrame(columns=['MemberId', 'ProviderId', 'DriveTimeMin'])\n    \n    return pd.DataFrame(valid_pairs, columns=['MemberId', 'ProviderId', 'DriveTimeMin'])\n\ndef interpret_capacity(providers: pd.DataFrame, members_count: int) -> pd.DataFrame:\n    \"\"\"Interpret provider availability as capacity\"\"\"\n    prov = providers.copy()\n    n_prov = max(1, len(providers))\n    avg_panel_size = max(1, int(round(members_count / n_prov)))\n    \n    def calc_cap(avail):\n        if avail <= 1.0:\n            return max(1, int(round(avail * avg_panel_size)))\n        return max(1, int(round(avail)))\n    \n    prov[\"Capacity\"] = prov[\"Availability\"].astype(float).fillna(0.0).apply(calc_cap)\n    return prov\n\ndef assign_greedy(members: pd.DataFrame, providers: pd.DataFrame, candidates: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Greedy assignment algorithm\"\"\"\n    if candidates.empty:\n        return pd.DataFrame(columns=[\"MemberId\", \"ProviderId\"])\n    \n    # Sort candidates by preference\n    cand = candidates.sort_values(\n        [\"MemberId\", \"DriveTimeMin\", \"CMS_Rating\", \"Cost\"], \n        ascending=[True, True, False, True]\n    )\n    \n    capacity_map = providers.set_index(\"ProviderId\")[\"Capacity\"].to_dict()\n    assignments = []\n    assigned_members = set()\n    \n    for _, row in cand.iterrows():\n        member_id = row['MemberId']\n        provider_id = row['ProviderId']\n        \n        if member_id not in assigned_members and capacity_map.get(provider_id, 0) > 0:\n            assignments.append((member_id, provider_id))\n            capacity_map[provider_id] -= 1\n            assigned_members.add(member_id)\n    \n    return pd.DataFrame(assignments, columns=[\"MemberId\", \"ProviderId\"])\n\ndef evaluate(assignments: pd.DataFrame, members: pd.DataFrame, providers: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"Evaluate assignment quality\"\"\"\n    total_members = len(members)\n    \n    if assignments.empty:\n        return {\n            \"coverage_pct\": 0.0,\n            \"avg_rating\": 0.0,\n            \"total_cost\": 0.0,\n            \"providers_used\": 0,\n            \"final_assignments\": pd.DataFrame()\n        }\n    \n    covered_members = assignments[\"MemberId\"].nunique()\n    coverage_pct = (covered_members / total_members * 100.0) if total_members else 0.0\n    \n    used_provider_counts = assignments[\"ProviderId\"].value_counts()\n    used_providers = providers[providers[\"ProviderId\"].isin(used_provider_counts.index)].copy()\n    \n    avg_rating = used_providers[\"CMS_Rating\"].mean() if not used_providers.empty else 0.0\n    total_cost = used_providers[\"Cost\"].sum() if not used_providers.empty else 0.0\n    \n    final_assignments = assignments.merge(\n        providers[[\"ProviderId\", \"ProviderType\", \"CMS_Rating\", \"Cost\"]], \n        on=\"ProviderId\"\n    )\n    \n    return {\n        \"coverage_pct\": float(coverage_pct),\n        \"avg_rating\": float(avg_rating),\n        \"total_cost\": float(total_cost),\n        \"providers_used\": len(used_providers),\n        \"final_assignments\": final_assignments\n    }\n\ndef compute_removal_priority(assignments: pd.DataFrame, candidates: pd.DataFrame, providers: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Compute provider removal priority scores\"\"\"\n    provider_assignments = assignments.groupby(\"ProviderId\")[\"MemberId\"].apply(list).to_dict()\n    member_alternatives = candidates.groupby(\"MemberId\")[\"ProviderId\"].nunique().to_dict()\n    \n    rows = []\n    for _, p in providers.iterrows():\n        assigned_mids = provider_assignments.get(p.ProviderId, [])\n        num_assigned = len(assigned_mids)\n        num_unique = sum(1 for mid in assigned_mids if member_alternatives.get(mid, 1) <= 1)\n        \n        cost_per_assigned = p.Cost / max(1, num_assigned)\n        score = cost_per_assigned - (p.CMS_Rating * 1000) + (num_unique * 10000)\n        \n        rows.append((p.ProviderId, score))\n    \n    return pd.DataFrame(rows, columns=[\"ProviderId\", \"Score\"]).sort_values(\"Score\", ascending=False)\n\nclass NetworkOptimizer:\n    \"\"\"Provider Network Optimizer with intelligent reassignment algorithm\"\"\"\n    \n    def __init__(self, max_drive_min=DEFAULT_MAX_DRIVE_MIN, min_coverage_pct=DEFAULT_MIN_COVERAGE_PCT, min_avg_rating=DEFAULT_MIN_AVG_RATING):\n        self.max_drive_min = max_drive_min\n        self.min_coverage_pct = min_coverage_pct\n        self.min_avg_rating = min_avg_rating\n        self.progress_handler = None\n        \n    def optimize(self, members: pd.DataFrame, providers: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Main optimization function\"\"\"\n        try:\n            logger.info(\"Starting network optimization...\")\n            \n            # Map and validate columns\n            providers_mapped = map_columns_providers(providers)\n            members_mapped = map_columns_members(members)\n            \n            # Run optimization\n            result = self._safe_prune(members_mapped, providers_mapped)\n            \n            logger.info(\"Network optimization completed successfully\")\n            return result\n            \n        except Exception as e:\n            logger.error(f\"Optimization failed: {str(e)}\")\n            raise\n    \n    def _safe_prune(self, members: pd.DataFrame, providers: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Enhanced optimization algorithm with incremental reassignment\"\"\"\n        providers_with_capacity = interpret_capacity(providers, len(members))\n        providers_with_types = apply_type_normalization(providers_with_capacity)\n        \n        # Pre-calculate all possible member-provider options\n        candidates = build_candidate_pairs(members, providers_with_types, self.max_drive_min)\n        if candidates.empty:\n            raise RuntimeError(f\"No viable member-provider pairs found within {self.max_drive_min} minutes.\")\n        \n        # Merge provider data into candidates for fast lookups\n        candidates_with_attrs = candidates.merge(\n            providers_with_types[[\"ProviderId\", \"CMS_Rating\", \"Cost\", \"Capacity\", \"ProviderType\"]], \n            on=\"ProviderId\"\n        )\n        \n        # Establish baseline\n        base_assign = assign_greedy(members, providers_with_types, candidates_with_attrs)\n        base_kpi = evaluate(base_assign, members, providers_with_types)\n        baseline_cost = base_kpi[\"total_cost\"]\n        \n        logger.info(f\"Baseline: coverage={base_kpi['coverage_pct']:.2f}% | avg_rating={base_kpi['avg_rating']:.2f} | cost=${baseline_cost:,.2f} | providers={base_kpi['providers_used']}\")\n        \n        if base_kpi[\"coverage_pct\"] < self.min_coverage_pct:\n            raise RuntimeError(f\"Baseline coverage is {base_kpi['coverage_pct']:.2f}%, below required {self.min_coverage_pct}%.\")\n        \n        removal_candidates = compute_removal_priority(base_assign, candidates, providers_with_types).head(MAX_REMOVAL_CANDIDATES)\n        logger.info(f\"Considering the top {MAX_REMOVAL_CANDIDATES} providers for removal...\")\n        \n        current_assignments = base_assign.copy()\n        current_providers_set = set(providers_with_types['ProviderId'])\n        removed_pids = []\n        \n        provider_info = providers_with_types.set_index('ProviderId')\n        \n        # Main optimization loop\n        for i, (_, row) in enumerate(removal_candidates.iterrows()):\n            if i % 50 == 0 and i > 0:\n                logger.info(f\"Processing removal candidate {i}/{len(removal_candidates)}...\")\n            \n            pid_to_remove = row.ProviderId\n            \n            # Fast check for type constraint violation\n            provider_type = provider_info.loc[pid_to_remove, 'ProviderType']\n            type_count = provider_info.loc[list(current_providers_set)].ProviderType.value_counts().get(provider_type, 0)\n            \n            if type_count - 1 < TYPE_MIN_COUNTS.get(provider_type, 0):\n                continue\n            \n            # Identify members who need reassignment\n            members_to_reassign = current_assignments[current_assignments['ProviderId'] == pid_to_remove]\n            \n            if members_to_reassign.empty:\n                # If provider had no assignments, we can safely remove them if cost is positive\n                if provider_info.loc[pid_to_remove, 'Cost'] > 0:\n                    current_providers_set.remove(pid_to_remove)\n                    removed_pids.append(pid_to_remove)\n                continue\n            \n            # Temporarily remove the provider and update assignments\n            trial_providers_set = current_providers_set - {pid_to_remove}\n            other_assignments = current_assignments[current_assignments['ProviderId'] != pid_to_remove]\n            \n            # Find new assignments ONLY for the displaced members\n            reassign_candidates = candidates_with_attrs[\n                candidates_with_attrs['MemberId'].isin(members_to_reassign['MemberId']) &\n                candidates_with_attrs['ProviderId'].isin(trial_providers_set)\n            ]\n            \n            # Fast, small-scale greedy assignment\n            new_assignments = assign_greedy(\n                members_to_reassign, \n                provider_info.loc[list(trial_providers_set)].reset_index(), \n                reassign_candidates\n            )\n            \n            # Combine to form the new trial assignment table\n            trial_assignments = pd.concat([other_assignments, new_assignments], ignore_index=True)\n            \n            # Evaluate trial\n            trial_kpi = evaluate(trial_assignments, members, provider_info.loc[list(trial_providers_set)].reset_index())\n            \n            # Accept if constraints are met\n            if (trial_kpi[\"coverage_pct\"] >= self.min_coverage_pct and \n                trial_kpi[\"avg_rating\"] >= self.min_avg_rating):\n                \n                current_assignments = trial_assignments\n                current_providers_set = trial_providers_set\n                removed_pids.append(pid_to_remove)\n                \n                # Log progress and update Streamlit if handler available\n                message = f\"Removed provider {pid_to_remove}. New cost: ${trial_kpi['total_cost']:,.2f}\"\n                logger.info(message)\n                if self.progress_handler:\n                    self.progress_handler.update_progress(message)\n        \n        # Final evaluation\n        final_providers = provider_info.loc[list(current_providers_set)].reset_index()\n        final_kpi = evaluate(current_assignments, members, final_providers)\n        \n        savings = baseline_cost - final_kpi[\"total_cost\"]\n        savings_pct = (savings / baseline_cost * 100) if baseline_cost > 0 else 0\n        \n        logger.info(f\"Optimization complete. Removed {len(removed_pids)} providers.\")\n        logger.info(f\"Final: coverage={final_kpi['coverage_pct']:.2f}% | avg_rating={final_kpi['avg_rating']:.2f} | cost=${final_kpi['total_cost']:,.2f} | savings=${savings:,.2f} ({savings_pct:.1f}%)\")\n        \n        return final_kpi","size_bytes":17893},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"numba>=0.61.2\",\n    \"numpy>=2.2.6\",\n    \"pandas>=2.3.2\",\n    \"plotly>=6.3.0\",\n    \"scipy>=1.16.1\",\n    \"streamlit>=1.48.1\",\n]\n","size_bytes":273},"replit.md":{"content":"# Provider Network Optimizer\n\n## Overview\n\nThe Provider Network Optimizer is a healthcare analytics dashboard built with Streamlit that helps optimize provider networks by analyzing spatial relationships between healthcare providers and members. The application processes CSV files containing provider and member data to determine optimal network configurations while maintaining coverage requirements and quality standards. It uses advanced algorithms including k-d trees for spatial queries and intelligent reassignment strategies to minimize network costs while ensuring adequate member access to care.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Frontend Architecture\n- **Streamlit Framework**: Web-based dashboard using Streamlit for the user interface\n- **Interactive Visualizations**: Plotly integration for creating dynamic charts and maps\n- **File Upload System**: CSV file processing with real-time validation and feedback\n- **Session State Management**: Persistent storage of optimization results and processed data across user interactions\n\n### Backend Architecture\n- **NetworkOptimizer Core Engine**: Main optimization logic using spatial algorithms and constraint satisfaction\n- **Data Processing Pipeline**: Pandas-based data manipulation with column mapping and validation\n- **Numba JIT Compilation**: Performance optimization for computationally intensive operations\n- **Spatial Computing**: cKDTree implementation for efficient nearest-neighbor searches\n\n### Data Storage Solutions\n- **In-Memory Processing**: Session-based data storage using Streamlit's session state\n- **CSV File Processing**: Direct file upload and processing without persistent database storage\n- **Temporary Data Structures**: NumPy arrays and Pandas DataFrames for runtime computations\n\n### Authentication and Authorization\n- **No Authentication System**: Direct access application without user management or access controls\n\n### Algorithm Design Patterns\n- **Incremental Reassignment**: Intelligent provider removal with member reassignment to maintain coverage\n- **Constraint Optimization**: Multi-objective optimization balancing cost reduction, coverage requirements, and quality thresholds\n- **Spatial Indexing**: K-d tree data structure for O(log n) provider lookup performance\n- **Type-Aware Processing**: Provider categorization system with minimum count requirements per type\n\n## External Dependencies\n\n### Core Libraries\n- **Streamlit**: Web application framework for the dashboard interface\n- **Pandas**: Data manipulation and analysis library\n- **NumPy**: Numerical computing for array operations and mathematical calculations\n- **SciPy**: Scientific computing library specifically using cKDTree for spatial operations\n\n### Visualization Libraries\n- **Plotly Express**: High-level plotting interface for charts and graphs\n- **Plotly Graph Objects**: Low-level plotting interface for custom visualizations\n\n### Performance Libraries\n- **Numba**: Just-in-time compilation for performance-critical numerical functions\n\n### Standard Libraries\n- **JSON**: Data serialization for configuration and results storage\n- **IO**: Input/output operations for file handling\n- **Logging**: Application logging and debugging\n- **Traceback**: Error handling and debugging support\n- **Typing**: Type hints for better code documentation and IDE support\n\n### Data Processing\n- **CSV File Support**: Direct processing of comma-separated value files\n- **Column Mapping System**: Flexible column name matching for various CSV formats\n- **Data Validation**: Built-in validation for required fields and data types","size_bytes":3656},"utils.py":{"content":"import pandas as pd\nfrom typing import Dict, Any, List\n\ndef validate_csv_structure(df: pd.DataFrame, file_type: str) -> Dict[str, Any]:\n    \"\"\"\n    Validate CSV file structure for provider or member data\n    \n    Args:\n        df: DataFrame to validate\n        file_type: 'provider' or 'member'\n    \n    Returns:\n        Dict with 'valid' boolean and 'message' string\n    \"\"\"\n    if df.empty:\n        return {'valid': False, 'message': f'{file_type} file is empty'}\n    \n    if file_type == 'provider':\n        return _validate_provider_structure(df)\n    elif file_type == 'member':\n        return _validate_member_structure(df)\n    else:\n        return {'valid': False, 'message': f'Unknown file type: {file_type}'}\n\ndef _validate_provider_structure(df: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"Validate provider CSV structure\"\"\"\n    required_columns = {\n        'id': ['providerid', 'provider_id', 'provider id', 'id'],\n        'latitude': ['latitude', 'lat', 'latt'],\n        'longitude': ['longitude', 'lon', 'lng']\n    }\n    \n    optional_columns = {\n        'rating': ['cmsrating', 'cms_rating', 'cms rating', 'rating', 'star'],\n        'cost': ['cost', 'annualcost', 'annual_cost', 'contractcost', 'contract_cost'],\n        'availability': ['availability', 'capacity', 'avail'],\n        'type': ['type', 'facilitytype', 'facility_type'],\n        'source': ['source']\n    }\n    \n    # Check for required columns\n    missing_required = []\n    df_columns_lower = [col.lower().replace(' ', '').replace('_', '') for col in df.columns]\n    \n    for field, candidates in required_columns.items():\n        found = False\n        for candidate in candidates:\n            if candidate.lower().replace(' ', '').replace('_', '') in df_columns_lower:\n                found = True\n                break\n        if not found:\n            missing_required.append(field)\n    \n    if missing_required:\n        return {\n            'valid': False, \n            'message': f'Missing required provider columns: {missing_required}. Available columns: {list(df.columns)}'\n        }\n    \n    # Validate data types for coordinates\n    lat_col = _find_column(df, required_columns['latitude'])\n    lon_col = _find_column(df, required_columns['longitude'])\n    \n    try:\n        pd.to_numeric(df[lat_col], errors='raise')\n        pd.to_numeric(df[lon_col], errors='raise')\n    except (ValueError, TypeError):\n        return {\n            'valid': False,\n            'message': 'Latitude and longitude columns must contain numeric values'\n        }\n    \n    return {'valid': True, 'message': 'Provider CSV structure is valid'}\n\ndef _validate_member_structure(df: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"Validate member CSV structure\"\"\"\n    required_columns = {\n        'id': ['memberid', 'member_id', 'member id', 'id'],\n        'latitude': ['latitude', 'lat'],\n        'longitude': ['longitude', 'lon', 'lng']\n    }\n    \n    # Check for required columns\n    missing_required = []\n    df_columns_lower = [col.lower().replace(' ', '').replace('_', '') for col in df.columns]\n    \n    for field, candidates in required_columns.items():\n        found = False\n        for candidate in candidates:\n            if candidate.lower().replace(' ', '').replace('_', '') in df_columns_lower:\n                found = True\n                break\n        if not found:\n            missing_required.append(field)\n    \n    if missing_required:\n        return {\n            'valid': False,\n            'message': f'Missing required member columns: {missing_required}. Available columns: {list(df.columns)}'\n        }\n    \n    # Validate data types for coordinates\n    lat_col = _find_column(df, required_columns['latitude'])\n    lon_col = _find_column(df, required_columns['longitude'])\n    \n    try:\n        pd.to_numeric(df[lat_col], errors='raise')\n        pd.to_numeric(df[lon_col], errors='raise')\n    except (ValueError, TypeError):\n        return {\n            'valid': False,\n            'message': 'Latitude and longitude columns must contain numeric values'\n        }\n    \n    return {'valid': True, 'message': 'Member CSV structure is valid'}\n\ndef _find_column(df: pd.DataFrame, candidates: List[str]) -> str:\n    \"\"\"Find column name from candidates\"\"\"\n    df_columns_lower = {col.lower().replace(' ', '').replace('_', ''): col for col in df.columns}\n    \n    for candidate in candidates:\n        key = candidate.lower().replace(' ', '').replace('_', '')\n        if key in df_columns_lower:\n            return df_columns_lower[key]\n    \n    # Fallback to exact match\n    for candidate in candidates:\n        if candidate in df.columns:\n            return candidate\n    \n    # Return first column name as fallback to ensure we always return a string\n    return df.columns[0] if len(df.columns) > 0 else \"\"\n\ndef get_sample_data_info() -> str:\n    \"\"\"Get sample data format information\"\"\"\n    return \"\"\"\n    ## Required CSV Format\n\n    ### Provider Data\n    **Required columns** (case-insensitive):\n    - `ProviderId` or `provider_id` or `id`: Unique provider identifier\n    - `Latitude` or `lat`: Provider latitude coordinate\n    - `Longitude` or `lon` or `lng`: Provider longitude coordinate\n\n    **Optional columns**:\n    - `CMS_Rating` or `rating` or `star`: Provider quality rating (1-5)\n    - `Cost` or `annual_cost`: Annual provider cost\n    - `Availability` or `capacity`: Provider capacity/availability\n    - `Type` or `facility_type`: Provider type/category\n    - `Source`: Data source information\n\n    ### Member Data  \n    **Required columns** (case-insensitive):\n    - `MemberId` or `member_id` or `id`: Unique member identifier\n    - `Latitude` or `lat`: Member latitude coordinate  \n    - `Longitude` or `lon` or `lng`: Member longitude coordinate\n\n    ### Data Tips\n    - Coordinates should be in decimal degrees format\n    - Provider costs should be numeric values\n    - Ratings should be between 1-5\n    - Missing optional fields will use reasonable defaults\n    \"\"\"\n\ndef format_currency(value: float) -> str:\n    \"\"\"Format value as currency\"\"\"\n    return f\"${value:,.2f}\"\n\ndef format_percentage(value: float) -> str:\n    \"\"\"Format value as percentage\"\"\"\n    return f\"{value:.1f}%\"\n\ndef format_rating(value: float) -> str:\n    \"\"\"Format rating value\"\"\"\n    return f\"{value:.2f}\"\n\ndef get_provider_type_colors() -> Dict[str, str]:\n    \"\"\"Get color mapping for provider types\"\"\"\n    return {\n        'hospital': '#FF6B6B',\n        'clinic': '#4ECDC4', \n        'nursing_home': '#45B7D1',\n        'scan_center': '#96CEB4',\n        'supplier_directory': '#FFEAA7',\n        'other': '#DDA0DD'\n    }\n\ndef create_summary_stats(assignments: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"Create summary statistics for assignments\"\"\"\n    if assignments.empty:\n        return {\n            'total_assignments': 0,\n            'unique_members': 0,\n            'unique_providers': 0,\n            'avg_rating': 0.0,\n            'total_cost': 0.0\n        }\n    \n    return {\n        'total_assignments': len(assignments),\n        'unique_members': assignments['MemberId'].nunique(),\n        'unique_providers': assignments['ProviderId'].nunique(),\n        'avg_rating': assignments['CMS_Rating'].mean() if 'CMS_Rating' in assignments.columns else 0.0,\n        'total_cost': assignments['Cost'].sum() if 'Cost' in assignments.columns else 0.0\n    }\n","size_bytes":7311}},"version":1}